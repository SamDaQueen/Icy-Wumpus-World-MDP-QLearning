# Icy-Wumpus-World-MDP-QLearning

<h4>Created as part of course CS5100-Foundations of Artificial Intelligence at Northeastern University</h4>

<div>

<p><em>The base code in 'ice.py' other than the 'get_valid_actions()', 'get_expexted_utility()', 'get_policy()', 'mdp_solve()',
'get_q_move()', 'get_q_policy()' and 'q_solve()' functions was provided by the professor of the course.</em></p><br>

<h3>Icy Wumpus World</h3>
<ul>
<li>A non-deterministic version of the Wumpus World problem with only golds and pits</li>
<li>Moving in any direction can land the agent one step, two steps, or three steps ahead according to some predefined probability</li>
<li>Hitting the wall while slipping will cause the agent to stop at the wall</li>
<li>For MDP and Q-Learning, reaching a pit or gold would end a trial, but if the agent slips past gold or pit, the trial does not end</li>
<li>The goal of the agent is to generate an optimal policy</li><br>
</ul>

<h3>Input</h3>
<h4>Input file pattern</h4>
MDP<br>
0.7 0.2 0.1<br>
- - P - -<br>
- - G P -<br>
- - P - -<br>
- - - - -<br>
<h4>Explanation</h4>
<ul>
<li>The first line of input will have 'MDP' or 'Q' written to indicate whether the problem is to be solved by MDP or Q-Learning</li>
<li>The second line contains the probabilities of moving one space, two spaces, and three spaces respectively</li>
<li>The rest of the file shows the Wumpus World grid with the position of golds(G) and pits(P)</li><br>
</ul>

<h3>Output</h3>
<h4>Output file pattern:</h4>
Reading mode...MDP<br>
Reading transition probabilities...<br>
D D P R D<br>
R R G P D<br>
U U P D D<br>
U U L L L<br>
Calculating average utility...<br>
Average utility per move: 7.51<br>
<h4>Explanation</h4>
<ul>
<li>The first line of output indicates whether 'MDP' or 'Q' was used to solve the problem</li>
<li>The second line mentions that the code is reading the transition probabilities</li>
<li>The grid represents the best policy the agent encountered in its trials. 
The values in grid, 'U', 'R', 'D', or 'L' represent the four directions 'Up', 'Right', 'Down', and 'Left' in which the agent should move if it is present in that position.</li>
<li>The best policy generated by the agent is tried and the average utility is calculated and printed on the last line</li><br>
</ul>

<h3>Files included</h3>

<ol>
<li>ice.py - Python code for the non-deterministic icy wumpus world environment and the policy calculation methods</li>
<li>Tests - contains few input files and their respective outputs</li>
<li>__MACOSX/tests - contains the same input files but for Mac</li>
</ol>

</div>
